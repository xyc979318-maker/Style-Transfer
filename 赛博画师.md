# 0.整体说明：

**首先，本次任务参考了李沐的计算机视觉一章（虽然好像学长的题就是这上面的，代码整体是按照书上所写的，但由于我不用jupyter，所以在输入，输出和一些细节上做了修改）**

一些学习笔记：

![2351bcdee3c22b18e8397a8d22b840a8](/Users/yichenxiang/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_99q37btm924h22_344f/temp/RWTemp/2025-10/9e20f478899dc29eb19741386f9343c8/2351bcdee3c22b18e8397a8d22b840a8.jpg)

![20ba63694af21a3962439a2fdd92c2f6](/Users/yichenxiang/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_99q37btm924h22_344f/temp/RWTemp/2025-10/9e20f478899dc29eb19741386f9343c8/20ba63694af21a3962439a2fdd92c2f6.jpg)

![e48539f94d7535a209a6832aaa8713aa](/Users/yichenxiang/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_99q37btm924h22_344f/temp/RWTemp/2025-10/9e20f478899dc29eb19741386f9343c8/e48539f94d7535a209a6832aaa8713aa.jpg)

![aca261a4e8a6aab82ff3727adc9f10a2](/Users/yichenxiang/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_99q37btm924h22_344f/temp/RWTemp/2025-10/9e20f478899dc29eb19741386f9343c8/aca261a4e8a6aab82ff3727adc9f10a2.jpg)

# 1.模型预训练与微调

## **模型预训练**与**模型微调**：

在上一个CNN大项目中，我就发现有时当我们的训练集大一点，epochs的次数多一点，亦或是我们构建的神经网络深一点时，即使用了gpu加速，我们还是经常会花十几分钟等待一个程序训练结束（正好打把王者（不是）），同时又因为很多时候我们给进去的图片呢数量是不够的，模型最后的结果也不好。但收集数据又是一个耗费大量精力（金钱）的事情，所以这当让是不好的。而这正是模型预训练和微调的意义。即把别人的模型放到自己的程序里。

但刚开始接触这个概念时，困扰我的最大问题是别人的训练样本和我们的又不一样，为什么可以迁移呢？查阅资料后我在李沐的书上看到的回答是这样的：**“尽管ImageNet数据集中的大多数图像与训练集无关，但在此数据集上训练的模型可能会提取更通用的图像特征，这有助于识别边缘、纹理、形状和对象组合。 这些类似的特征也可能有效地识别椅子”**，但同时我们当让也不能直接使用这一模型，因为我们希望神经网络输出的结果总是随着类别，目的等发生这改变的。使用我们就要使用微调。具体而言，对我们的模型，我们复制前L-1层的参数，但最后一次我们初始化其参数，然后用训练集训练这一层的参数。（其实从这一做法上我们也能联想一件事，就是距离输出层越近的更能反映整体，而离输入层近的更关注局部）。

## **冻结参数**的作用：

而就是我们上面说的，哪些复制过来的层的参数就是冻结参数，换言之，这些参数在训练时是不会发生变化的。题目中问它的作用，但我认为它不叫做有作用，如果这些参数冻结，那和从头训练又有什么区别呢？当然补充一点，如果我们只是复制别人的网络结构，那在别人大训练集下表现良好的神经网络在你这大概率会过拟合。

## 微调时超参数该如何设置：

而模型微调的本质其实还是神经网络，所以它的参数也就还是学习率，优化器，epochs，batch_size，这里就不展开介绍来。

## **在风格迁移领域预训练模型有什么作用**：

其实我认为在绝大部分的情况下，微调的作用都是相似的，也就是花更少的时间得到一个更好的模型。在学习时，我在微调下写的是“站在巨人的肩膀上”，其实在风格迁移中的作用是一样的。

## 使用预训练模型进行微调的效果会比从零开始训练更差：

相较而言，我们更应关心风格迁移什么时候不能使用。我认为最主要的一点是你的训练集与你像使用的微调模型使用的训练集完全无关时，你去使用微调可能反而会对你的模型造成一些干扰。

## 除了微调，还有哪些利用预训练模型的方法：

### **预训练权重作为初始化**：

其实这种初始化也很好理解，就是虽然我仍然复制一个训练好的网络的权重，但我在训练时仍然可以改变它，这在保证模型神经网络的可靠性的（给了模型更高的自由度）的同时可以加快loss趋于稳定的速度。（更快收敛）

### **适配器**：

它相当于是直复制特定的层的权重

**总的来说，预训练模型和预制菜很像，都是把已经训练好的模型复制到新的模型里。（只是复制到多少回方式有所不同）**

# 代码思路：

## 如果所选的风格图片和内容图片尺寸相差太大，会有影响吗？

如果只是一点的差别是可以解决的，我们可以直接在预处理的时候将其resize到同一大下，但如果太大肯定是不行的，第一个问题就是在resize时，如果我们的style—img太小，那么经过放大后必然导致主线色块（几个像素都是同样的颜色），那这样的话我们的style和原始的style肯定是不同的。同理对于content也是一样的。进一步来说，Gram矩阵计算风格统计特征时，会受到特征图尺寸的影响，这个我们放到gram里面再说。

## 2.**内容损失、风格损失、全变分损失**的数学原理：

### **1.内容损失：**

简单来说，我们要衡量的就是现在的生成图像和内容图像之间的差别，而我们在上CNN中知道本质上而言，图像可以转换为一个三通道的矩阵（RGB），如果这两个矩阵一样，那么输出的画面也就是一样的，而他们之间的差别就可以用两个矩阵的差别来衡量，使用我们也就只需要像线性回归一样，求均方误差就可以了。

### 2.风格损失：

风格损失通过比较**特征统计量**（Gram矩阵）来衡量风格相似性。那什么是gram矩阵呢，而为什么内积能表示两个通道间的相似度？这我们就先来回答三个问题。实现gram矩阵通过X·X.T来反映xi和xj的内积，这是简单的矩阵乘法。而我们有知道，内积可以表示为两个向量的模长乘以夹角，在我们认为在不同的通道上两者的模长区别不大，则gram与角度相关，而角度越小，两者的相关性也就越大，故gram可以反映不同的通道（RGB）之间的差异化的大小，进而决定色彩风格的倾向，而预测值和style两者的均方误差就可以反映风格差异了。

### 3.全变分损失：

简单来说，这个损失就是用来抑制噪点的。什么意思呢？如果我们单纯考虑上面的两种损失，那么就很有可能出现一个地方的像素特别暗或者亮，而解决的方法就是加入全变分损失。使用我们要比较多就是其余相邻点点绝对值不能太大，故全变分损失就如下：

![4da8c673-1dbf-46eb-bf04-219028b04c5e](/Users/yichenxiang/Library/Containers/com.tencent.xinWeChat/Data/Documents/xwechat_files/wxid_99q37btm924h22_344f/temp/InputTemp/4da8c673-1dbf-46eb-bf04-219028b04c5e.png)

## 内容损失和风格损失都要求从**计算图**中分离，如果不这样做，会有什么后果？

首先我们要明白什么是从计算图中分类，我的理解就是不让反向传播进过他们。这也很好理解，试想，如果我们不分离，那方向传播很有可能不仅优化了我们的生成图像，还有可能是优化了内容图像和风格图像，这不就完蛋了，故我们需要在方向传播前先分类内容损失和风格损失（阻止其优化风格图像和内容图像）

## 使用迁移学习来提取特征时应设置为训练模式还是评估模式？

应选择评估模式，这是因为评估模式会固定模型中的归一化层和Dropout层的行为：归一化层将使用训练阶段统计得到的全局均值和方差进行归一化，而不是基于当前小批量数据计算；Dropout层则会停止随机丢弃神经元，确保所有神经元都参与前向计算。而当然，对于迁移学习，我们更关注的是整体而不是小批量。

## 如何从模型中抽取合适的层作为**内容层和风格层**，这样做的依据是什么？

首先我们要明白，越靠近输入层越接近局部细节，越靠近输出层越接近整体。故在选择内容层的时候，我们当然要选择靠近输出层的层作为内容层。但何为风格，它可能是局部的色彩对比，也可能是比较整体性的笔触风格，所以我们可以隔几层就选则一个风格层。具体而言，在本次项目中，我是在vgg—19模型上进行的微调，而我选的内容层是[25],风格层是[0，5，10，19，28]

## 风格迁移任务中适合使用哪种优化方法，相较于**Adam、SGD**的特点是什么？（当然，你可以选择后两种方法）

首先要开始实现这个项目时我是直接使用的就是Adam（主要是也不知道有其他的优化器），但后来我去了解了另一种优化器。

###  LBFGS：

其与其它优化算法最主要的区别就是梯度下降方式的区别。对于传统的SGD和Adam，都是沿着切线方向下降（lr*f‘（x）），但LBFS使用的是牛顿法（计算二阶导数矩阵）的方法进行下降。理论上来说它在风格迁移任务中的效果会比adam好，但尝试后我发现LBFGS的速度太慢，而其优化效果相较与Adam区别并不大，故在本次任务中我最好依然选择了使用Adam

## 简述风格迁移中**前向传播和反向传播**的流程：

前向传播：此时我们不能直接使用Sequential来进行前向传播，原因是我们不仅需要最终的输出层，我们还需要导出其中中间层的输出，所以在这里我们需要逐层计算并返回需要的值。

反向传播就比较简单，我们先计算总的损失，再自动求导（微分），让后使用优化器即可。

## 模型的总损失越小迁移效果越好吗？各个损失间的权重、超参数该如何设置？

第一个问题我认为答案是当然的，如果我们不希望最后的总损失越小，那么我们的梯度下降算法（优化）的意义又在什么地方呢？所以我们肯定希望总的损失越小越好。但总的损失一定就是将三种损失都相加吗？当然不行，因为我们发现风格损失即使值较小，也能带来很大的影响，使用我们如果直接将损失相加，我们就会得到大概率不在意风格损失的模型，这当然就不是我们想要的。故最重要的就是在三者前加上一定的权重来平衡三者的关系（在PINN中也有相似的应用）

而如何设置我是根据训练的结果来调整的，还有一些超参数如lr，epoch等，就和前面的MLP中是设置思路很像，但由于我们使用的是Adam优化器，所以lr可以设的小一点（如0.001）

# 代码：

![image-20251006145446768](/Users/yichenxiang/Library/Application Support/typora-user-images/image-20251006145446768.png)

![image-20251006145509809](/Users/yichenxiang/Library/Application Support/typora-user-images/image-20251006145509809.png)

![image-20251006145533959](/Users/yichenxiang/Library/Application Support/typora-user-images/image-20251006145533959.png)

![image-20251006145551012](/Users/yichenxiang/Library/Application Support/typora-user-images/image-20251006145551012.png)

![image-20251006151316681](/Users/yichenxiang/Library/Application Support/typora-user-images/image-20251006151316681.png)

# **图片展示：**

风格图像我使用的是我暑假在上海美术馆看到的![0W0A0823](/Users/yichenxiang/Pictures/佳能r52_ 广东实验中学/0W0A0823.JPG)

但当我想直接使用我自己拍摄的画时，我发现了一个很大的问题，就是我这幅画是带画框的，且我这幅画的分辨率太高，使用导致训练的结果就很奇怪，使用我最终选择在网上找了幅笔触和这幅很像的![梵高自画像](/Users/yichenxiang/Desktop/xyc/python/线性回归/计算机视觉/梵高自画像.jpg)

（是梵高的另一幅自画像）

让后我就找到一副很有反差的画？

![初音](/Users/yichenxiang/Desktop/xyc/python/线性回归/计算机视觉/初音.jpg)

最后得到的结果是（^_^）

![风格迁移图像](/Users/yichenxiang/Desktop/xyc/python/线性回归/计算机视觉/风格迁移图像.jpg![风格迁移图像](/Users/yichenxiang/Desktop/xyc/python/线性回归/计算机视觉/风格迁移图像.jpg)

（感觉笔触的特点还不是特别明显，但当我继续加大style的权重得到的图片只是噪点变的更多，内容不好看而已（😢）

![image-20251006152606247](/Users/yichenxiang/Library/Application Support/typora-user-images/image-20251006152606247.png)

（程序的自动输出）

